{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18728d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Victory Mansions is a dilapidated building where Winston resides. It has cramped living conditions, faulty plumbing, and electricity issues. The apartments are small and run-down with peeling wallpaper and worn-out furniture. The building is located in a dreary and oppressive environment, reflecting the bleak atmosphere of the society in which Winston lives. The hallway smells of boiled cabbage and old rag mats, with a large colored poster of a man\\'s face at one end. There are seven flights of stairs, and the elevator is rarely working. Each landing has a poster saying \"BIG BROTHER IS WATCHING YOU.\" The building has a roof from which you can see other buildings, including the Ministry of Truth, and is surrounded by a grimy landscape with rotting houses and bombed sites. Inside Winston\\'s flat, there is a telescreen that cannot be completely shut off, constantly broadcasting information.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to patch https://api.smith.langchain.com/runs/0dc5be41-68b5-47a6-9a59-d8f6a962c367 in LangSmith API. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/runs/0dc5be41-68b5-47a6-9a59-d8f6a962c367', '{\"error\":\"Conflict: payload already received: payloads already received\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"../../.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"../../files/chapter_one.docx\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            Use the following portion of a long document to see if any of the\n",
    "            text is relevent to answer the question. Return any relevant text\n",
    "            verbatim.\n",
    "            -------\n",
    "            {context}\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"human\",\"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "def map_docs(inputs):\n",
    "    documents = inputs['documents']\n",
    "    question = inputs['question']\n",
    "\n",
    "    return \"\\n\\n\".join(\n",
    "        map_doc_chain.invoke(\n",
    "            {\n",
    "                \"context\": doc.page_content,\n",
    "                \"question\": question\n",
    "            }\n",
    "        ).content\n",
    "        for doc in documents\n",
    "    )\n",
    "\n",
    "map_chain = { \n",
    "    \"documents\": retriever, \n",
    "    \"question\": RunnablePassthrough(),\n",
    "    } | RunnableLambda(map_docs)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            Given the following extracted parts of a long document and a\n",
    "            question, create a final answer.\n",
    "            If you don't know the answer, just say that you don't know. Don't try\n",
    "            to make up an answer.\n",
    "            -------\n",
    "            {context}\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"human\",\"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = {\"context\":map_chain, \"question\": RunnablePassthrough()} | final_prompt | llm\n",
    "\n",
    "chain.invoke(\"Describe Victory Mansions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911d588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
